{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = 'data3/'\n",
    "        \n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='sagemaker-ap-southeast-1-876828306900'\n",
    "data_key = 'balanceddfsmaller.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "\n",
    "\n",
    "balanceddf=pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=balanceddf[\"article_text\"]\n",
    "Y=balanceddf.iloc[:,-1]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le =LabelEncoder()\n",
    "y_traint=le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y_traint,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_trainVectorized=vectorizer.fit_transform(X_train)\n",
    "X_testVectorized=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainVectorizedTF_array=X_trainVectorized.toarray()\n",
    "X_testVectorizedTF_array=X_testVectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testVectorizedTF_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 25451)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainVectorizedTF_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(y_train),pd.DataFrame(X_trainVectorizedTF_array)], axis=1)\\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'),header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_testVectorizedTF_array).to_csv(os.path.join(data_dir, 'test.csv'),header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-876828306900/bias2\n"
     ]
    }
   ],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'data3/'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = \"bias2\"\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cost/20200301-20200401/cost-Manifest.json\n",
      "/cost/20200301-20200401/dc01c63d-c9ca-4e6f-ac30-ba7d487ffbe8/cost-1.csv.gz\n",
      "/cost/20200301-20200401/dc01c63d-c9ca-4e6f-ac30-ba7d487ffbe8/cost-Manifest.json\n",
      "/cost/20200401-20200501/1080bd04-2efa-45d5-8e23-d1ab23de7075/cost-1.csv.gz\n",
      "/cost/20200401-20200501/1080bd04-2efa-45d5-8e23-d1ab23de7075/cost-Manifest.json\n",
      "/cost/20200401-20200501/1186c0a3-6c6e-41b3-aa67-cab1aa07e333/cost-1.csv.gz\n",
      "/cost/20200401-20200501/1186c0a3-6c6e-41b3-aa67-cab1aa07e333/cost-Manifest.json\n",
      "/cost/20200401-20200501/148828dd-b857-490a-8437-6d227dcf4c8c/cost-1.csv.gz\n",
      "/cost/20200401-20200501/148828dd-b857-490a-8437-6d227dcf4c8c/cost-Manifest.json\n",
      "/cost/20200401-20200501/1d9d94fd-b338-49a7-831f-d8a96b13647d/cost-1.csv.gz\n",
      "/cost/20200401-20200501/1d9d94fd-b338-49a7-831f-d8a96b13647d/cost-Manifest.json\n",
      "/cost/20200401-20200501/2c05340a-39d3-48ef-a7ec-173e962e66ba/cost-1.csv.gz\n",
      "/cost/20200401-20200501/2c05340a-39d3-48ef-a7ec-173e962e66ba/cost-Manifest.json\n",
      "/cost/20200401-20200501/2cea2451-9d2f-44f1-9872-9048e2c35899/cost-1.csv.gz\n",
      "/cost/20200401-20200501/2cea2451-9d2f-44f1-9872-9048e2c35899/cost-Manifest.json\n",
      "/cost/20200401-20200501/5d754190-6437-4cb8-b2ec-d2de2246ba99/cost-1.csv.gz\n",
      "/cost/20200401-20200501/5d754190-6437-4cb8-b2ec-d2de2246ba99/cost-Manifest.json\n",
      "/cost/20200401-20200501/7fbca4e7-0658-4f1d-80e8-ff6e250604c8/cost-1.csv.gz\n",
      "/cost/20200401-20200501/7fbca4e7-0658-4f1d-80e8-ff6e250604c8/cost-Manifest.json\n",
      "/cost/20200401-20200501/a27b8155-78dc-4cfa-8a8b-57012d8b1ab0/cost-1.csv.gz\n",
      "/cost/20200401-20200501/a27b8155-78dc-4cfa-8a8b-57012d8b1ab0/cost-Manifest.json\n",
      "/cost/20200401-20200501/cost-Manifest.json\n",
      "/cost/20200401-20200501/f50565a3-7040-4eee-aca9-10732ba2e71a/cost-1.csv.gz\n",
      "/cost/20200401-20200501/f50565a3-7040-4eee-aca9-10732ba2e71a/cost-Manifest.json\n",
      "aws-programmatic-access-test-object\n",
      "balanceddfsmaller.csv\n",
      "bias/output/xgboost-2020-04-25-08-39-55-103/output/model.tar.gz\n",
      "bias/output/xgboost-2020-04-25-08-49-06-541/output/model.tar.gz\n",
      "bias/output/xgboost-2020-04-25-09-08-41-585/output/model.tar.gz\n",
      "bias/output/xgboost-2020-04-26-03-46-03-947/output/model.tar.gz\n",
      "bias/output/xgboost-2020-04-26-04-19-45-595/output/model.tar.gz\n",
      "bias/test.csv\n",
      "bias/test.csv.out\n",
      "bias/train.csv\n",
      "bias1/output/xgboost-2020-04-26-09-54-46-955/output/model.tar.gz\n",
      "bias1/output/xgboost-2020-04-27-08-46-06-128/output/model.tar.gz\n",
      "bias1/output/xgboost-2020-04-27-08-56-36-541/output/model.tar.gz\n",
      "bias1/test.csv\n",
      "bias1/test.csv.out\n",
      "bias1/train.csv\n",
      "bias2/test.csv\n",
      "bias2/train.csv\n",
      "sagemaker-pytorch-2020-04-25-08-21-48-975/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2020-04-25-08-26-19-828/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-04-25-05-56-05-384/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-04-25-05-57-41-545/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-04-25-07-03-23-925/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-04-25-07-12-41-993/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-04-25-07-38-45-394/source/sourcedir.tar.gz\n",
      "sagemaker/bias_rnn/cleantransformerjob.csv\n",
      "sagemaker/bias_rnn/output/xgboost-2020-04-14-07-58-39-800/output/model.tar.gz\n",
      "sagemaker/bias_rnn/output/xgboost-2020-04-23-01-51-50-352/output/model.tar.gz\n",
      "sagemaker/bias_rnn/test.csv\n",
      "sagemaker/bias_rnn/trainfinal.csv\n",
      "sagemaker/bias_rnn/transformerjob.csv\n",
      "xgboost-2020-04-23-03-30-30-486/test.csv.out\n",
      "xgboost-2020-04-25-09-35-11-927/test.csv.out\n",
      "xgboost-2020-04-26-03-50-00-123/test.csv.out\n",
      "xgboost-2020-04-26-04-09-02-447/test.csv.out\n",
      "xgboost-2020-04-26-04-22-58-321/test.csv.out\n",
      "xgboost-2020-04-26-04-46-06-775/test.csv.out\n",
      "xgboost-2020-04-26-09-58-15-342/test.csv.out\n",
      "xgboost-2020-04-27-08-50-10-758/test.csv.out\n",
      "xgboost-2020-04-27-09-04-42-437/test.csv.out\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = sagemaker_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-876828306900/bias2/train.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='0.90-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '0.90-1').\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(sagemaker_session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    train_instance_count=1,                  # How many compute instances\n",
    "                                    train_instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(sagemaker_session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=sagemaker_session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        \n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-27 09:16:46 Starting - Starting the training job...\n",
      "2020-04-27 09:16:48 Starting - Launching requested ML instances......\n",
      "2020-04-27 09:18:15 Starting - Preparing the instances for training......\n",
      "2020-04-27 09:19:10 Downloading - Downloading input data...\n",
      "2020-04-27 09:19:45 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:19:46:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:19:46:INFO] Path /opt/ml/input/data/validation does not exist!\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:19:46:INFO] File size need to be processed in the node: 81.26mb. Available memory size in the node: 8508.74mb\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:19:46:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[09:19:46] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[09:19:46] 800x25451 matrix with 20360800 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[09:19:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.28375\u001b[0m\n",
      "\u001b[34mWill train until train-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[09:19:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.24375\u001b[0m\n",
      "\u001b[34m[09:19:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.24875\u001b[0m\n",
      "\u001b[34m[09:19:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.22625\u001b[0m\n",
      "\u001b[34m[09:19:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.20875\u001b[0m\n",
      "\u001b[34m[09:19:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.205\u001b[0m\n",
      "\u001b[34m[09:19:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.18875\u001b[0m\n",
      "\u001b[34m[09:19:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.17625\u001b[0m\n",
      "\u001b[34m[09:19:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.16625\u001b[0m\n",
      "\u001b[34m[09:19:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.1575\u001b[0m\n",
      "\u001b[34m[09:19:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.15625\u001b[0m\n",
      "\u001b[34m[09:19:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.145\u001b[0m\n",
      "\u001b[34m[09:19:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.14\u001b[0m\n",
      "\u001b[34m[09:19:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.13625\u001b[0m\n",
      "\u001b[34m[09:19:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.1225\u001b[0m\n",
      "\u001b[34m[09:19:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.115\u001b[0m\n",
      "\u001b[34m[09:19:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.1075\u001b[0m\n",
      "\u001b[34m[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.1\u001b[0m\n",
      "\u001b[34m[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.0975\u001b[0m\n",
      "\u001b[34m[09:19:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.09625\u001b[0m\n",
      "\u001b[34m[09:19:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.09125\u001b[0m\n",
      "\u001b[34m[09:19:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.08625\u001b[0m\n",
      "\u001b[34m[09:19:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.08875\u001b[0m\n",
      "\u001b[34m[09:19:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.07625\u001b[0m\n",
      "\u001b[34m[09:19:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.075\u001b[0m\n",
      "\u001b[34m[09:19:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.0725\u001b[0m\n",
      "\u001b[34m[09:19:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.06875\u001b[0m\n",
      "\u001b[34m[09:19:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.0675\u001b[0m\n",
      "\u001b[34m[09:19:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.0625\u001b[0m\n",
      "\u001b[34m[09:19:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 10 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.06375\u001b[0m\n",
      "\u001b[34m[09:19:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.0575\u001b[0m\n",
      "\u001b[34m[09:19:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.0575\u001b[0m\n",
      "\u001b[34m[09:19:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.05625\u001b[0m\n",
      "\u001b[34m[09:19:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.055\u001b[0m\n",
      "\u001b[34m[09:19:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.05375\u001b[0m\n",
      "\u001b[34m[09:20:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.05125\u001b[0m\n",
      "\u001b[34m[09:20:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 2 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.04875\u001b[0m\n",
      "\u001b[34m[09:20:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.04875\u001b[0m\n",
      "\u001b[34m[09:20:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 12 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.04875\u001b[0m\n",
      "\u001b[34m[09:20:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.0475\u001b[0m\n",
      "\u001b[34m[09:20:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.045\u001b[0m\n",
      "\u001b[34m[09:20:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.045\u001b[0m\n",
      "\u001b[34m[09:20:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 14 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.045\u001b[0m\n",
      "\u001b[34m[09:20:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.0425\u001b[0m\n",
      "\u001b[34m[09:20:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.04\u001b[0m\n",
      "\u001b[34m[09:20:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 18 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.04125\u001b[0m\n",
      "\u001b[34m[09:20:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.04125\u001b[0m\n",
      "\u001b[34m[09:20:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.03875\u001b[0m\n",
      "\u001b[34m[09:20:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 6 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.04\u001b[0m\n",
      "\u001b[34m[09:20:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.03625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-04-27 09:20:16 Uploading - Uploading generated training model\u001b[34m[09:20:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.0375\u001b[0m\n",
      "\u001b[34m[09:20:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.035\u001b[0m\n",
      "\u001b[34m[09:20:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.035\u001b[0m\n",
      "\u001b[34m[09:20:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.035\u001b[0m\n",
      "\u001b[34m[09:20:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.035\u001b[0m\n",
      "\u001b[34m[09:20:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.03625\u001b[0m\n",
      "\u001b[34m[09:20:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.0325\u001b[0m\n",
      "\u001b[34m[09:20:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.0325\u001b[0m\n",
      "\u001b[34m[09:20:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.0325\u001b[0m\n",
      "\u001b[34m[09:20:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34m[09:20:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.03125\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.03125\n",
      "\u001b[0m\n",
      "\n",
      "2020-04-27 09:20:23 Completed - Training job completed\n",
      "Training seconds: 73\n",
      "Billable seconds: 73\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location = sagemaker_session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-876828306900/bias2/test.csv\n"
     ]
    }
   ],
   "source": [
    "print(test_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create transformer object\n",
    "\n",
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:11 +0000] [1] [INFO] Starting gunicorn 19.7.1\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:11 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:11 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:11 +0000] [39] [INFO] Booting worker with pid: 39\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:11 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:12 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2020-04-27 09:26:12 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:12:INFO] Model loaded successfully for worker : 40\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:12:INFO] Model loaded successfully for worker : 39\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:12:INFO] Model loaded successfully for worker : 41\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:12:INFO] Model loaded successfully for worker : 42\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:31:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:31:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:31:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:31:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2020-04-27T09:26:31.113:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:32:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:32:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2020-04-27:09:26:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2020-04-27:09:26:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2.9 KiB/2.9 KiB (44.2 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-ap-southeast-1-876828306900/xgboost-2020-04-27-09-23-00-018/test.csv.out to data3/test.csv.out\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "predictions = [round(num) for num in predictions.squeeze().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68       101\n",
      "           1       0.67      0.61      0.64        99\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.66      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>test our model again using the newly deployed endpoint<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Using already existing model: xgboost-2020-04-27-09-16-46-689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# We need to tell the endpoint what format the data we are sending is in so that SageMaker can perform the serialization.\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer\n",
    "xgb_predictor.deserializer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def predict(data, rows=50):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')\n",
    "\n",
    "test_data = pd.read_csv(os.path.join(data_dir, 'test.csv'), header=None)\n",
    "\n",
    "predictions = predict(test_data.as_matrix()[:, 1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.495"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = [round(num) for num in predictions]\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       101\n",
      "           1       0.49      1.00      0.66        99\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       200\n",
      "   macro avg       0.25      0.50      0.33       200\n",
      "weighted avg       0.25      0.49      0.33       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
